{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6b2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, I follow techniques from kaggle.com/SHYAMBHUMUKHERJEE.\n",
    "# Used this as a guidebook to advanced nlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cac4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79317916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"C:/Users/user/OneDrive/Desktop/nlp_twitter/nlp-getting-started/nlp_twitter_train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/user/OneDrive/Desktop/nlp_twitter/nlp-getting-started/nlp_twitter_test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9817e138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57df9bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6404c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "test = test.drop(columns = ['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef4ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0     NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1     NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "2     NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "3     NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "4     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c84343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['target'])\n",
    "print(train['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0865efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "wordLemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91da339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna('')\n",
    "test = test.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db6440",
   "metadata": {},
   "source": [
    "# Keyword Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5032325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'ablaze',\n",
       " 'accident',\n",
       " 'aftershock',\n",
       " 'airplane%20accident',\n",
       " 'ambulance',\n",
       " 'annihilated',\n",
       " 'annihilation',\n",
       " 'apocalypse',\n",
       " 'armageddon',\n",
       " 'army',\n",
       " 'arson',\n",
       " 'arsonist',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'avalanche',\n",
       " 'battle',\n",
       " 'bioterror',\n",
       " 'bioterrorism',\n",
       " 'blaze',\n",
       " 'blazing',\n",
       " 'bleeding',\n",
       " 'blew%20up',\n",
       " 'blight',\n",
       " 'blizzard',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blown%20up',\n",
       " 'body%20bag',\n",
       " 'body%20bagging',\n",
       " 'body%20bags',\n",
       " 'bomb',\n",
       " 'bombed',\n",
       " 'bombing',\n",
       " 'bridge%20collapse',\n",
       " 'buildings%20burning',\n",
       " 'buildings%20on%20fire',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burning%20buildings',\n",
       " 'bush%20fires',\n",
       " 'casualties',\n",
       " 'casualty',\n",
       " 'catastrophe',\n",
       " 'catastrophic',\n",
       " 'chemical%20emergency',\n",
       " 'cliff%20fall',\n",
       " 'collapse',\n",
       " 'collapsed',\n",
       " 'collide',\n",
       " 'collided',\n",
       " 'collision',\n",
       " 'crash',\n",
       " 'crashed',\n",
       " 'crush',\n",
       " 'crushed',\n",
       " 'curfew',\n",
       " 'cyclone',\n",
       " 'damage',\n",
       " 'danger',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'deaths',\n",
       " 'debris',\n",
       " 'deluge',\n",
       " 'deluged',\n",
       " 'demolish',\n",
       " 'demolished',\n",
       " 'demolition',\n",
       " 'derail',\n",
       " 'derailed',\n",
       " 'derailment',\n",
       " 'desolate',\n",
       " 'desolation',\n",
       " 'destroy',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'detonate',\n",
       " 'detonation',\n",
       " 'devastated',\n",
       " 'devastation',\n",
       " 'disaster',\n",
       " 'displaced',\n",
       " 'drought',\n",
       " 'drown',\n",
       " 'drowned',\n",
       " 'drowning',\n",
       " 'dust%20storm',\n",
       " 'earthquake',\n",
       " 'electrocute',\n",
       " 'electrocuted',\n",
       " 'emergency',\n",
       " 'emergency%20plan',\n",
       " 'emergency%20services',\n",
       " 'engulfed',\n",
       " 'epicentre',\n",
       " 'evacuate',\n",
       " 'evacuated',\n",
       " 'evacuation',\n",
       " 'explode',\n",
       " 'exploded',\n",
       " 'explosion',\n",
       " 'eyewitness',\n",
       " 'famine',\n",
       " 'fatal',\n",
       " 'fatalities',\n",
       " 'fatality',\n",
       " 'fear',\n",
       " 'fire',\n",
       " 'fire%20truck',\n",
       " 'first%20responders',\n",
       " 'flames',\n",
       " 'flattened',\n",
       " 'flood',\n",
       " 'flooding',\n",
       " 'floods',\n",
       " 'forest%20fire',\n",
       " 'forest%20fires',\n",
       " 'hail',\n",
       " 'hailstorm',\n",
       " 'harm',\n",
       " 'hazard',\n",
       " 'hazardous',\n",
       " 'heat%20wave',\n",
       " 'hellfire',\n",
       " 'hijack',\n",
       " 'hijacker',\n",
       " 'hijacking',\n",
       " 'hostage',\n",
       " 'hostages',\n",
       " 'hurricane',\n",
       " 'injured',\n",
       " 'injuries',\n",
       " 'injury',\n",
       " 'inundated',\n",
       " 'inundation',\n",
       " 'landslide',\n",
       " 'lava',\n",
       " 'lightning',\n",
       " 'loud%20bang',\n",
       " 'mass%20murder',\n",
       " 'mass%20murderer',\n",
       " 'massacre',\n",
       " 'mayhem',\n",
       " 'meltdown',\n",
       " 'military',\n",
       " 'mudslide',\n",
       " 'natural%20disaster',\n",
       " 'nuclear%20disaster',\n",
       " 'nuclear%20reactor',\n",
       " 'obliterate',\n",
       " 'obliterated',\n",
       " 'obliteration',\n",
       " 'oil%20spill',\n",
       " 'outbreak',\n",
       " 'pandemonium',\n",
       " 'panic',\n",
       " 'panicking',\n",
       " 'police',\n",
       " 'quarantine',\n",
       " 'quarantined',\n",
       " 'radiation%20emergency',\n",
       " 'rainstorm',\n",
       " 'razed',\n",
       " 'refugees',\n",
       " 'rescue',\n",
       " 'rescued',\n",
       " 'rescuers',\n",
       " 'riot',\n",
       " 'rioting',\n",
       " 'rubble',\n",
       " 'ruin',\n",
       " 'sandstorm',\n",
       " 'screamed',\n",
       " 'screaming',\n",
       " 'screams',\n",
       " 'seismic',\n",
       " 'sinkhole',\n",
       " 'sinking',\n",
       " 'siren',\n",
       " 'sirens',\n",
       " 'smoke',\n",
       " 'snowstorm',\n",
       " 'storm',\n",
       " 'stretcher',\n",
       " 'structural%20failure',\n",
       " 'suicide%20bomb',\n",
       " 'suicide%20bomber',\n",
       " 'suicide%20bombing',\n",
       " 'sunk',\n",
       " 'survive',\n",
       " 'survived',\n",
       " 'survivors',\n",
       " 'terrorism',\n",
       " 'terrorist',\n",
       " 'threat',\n",
       " 'thunder',\n",
       " 'thunderstorm',\n",
       " 'tornado',\n",
       " 'tragedy',\n",
       " 'trapped',\n",
       " 'trauma',\n",
       " 'traumatised',\n",
       " 'trouble',\n",
       " 'tsunami',\n",
       " 'twister',\n",
       " 'typhoon',\n",
       " 'upheaval',\n",
       " 'violent%20storm',\n",
       " 'volcano',\n",
       " 'war%20zone',\n",
       " 'weapon',\n",
       " 'weapons',\n",
       " 'whirlwind',\n",
       " 'wild%20fires',\n",
       " 'wildfire',\n",
       " 'windstorm',\n",
       " 'wounded',\n",
       " 'wounds',\n",
       " 'wreck',\n",
       " 'wreckage',\n",
       " 'wrecked']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list out all keywords\n",
    "keywords = list(train['keyword'].unique())\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6762cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove %20 from keyword\n",
    "import re\n",
    "def CleanedKeyword(x):\n",
    "    try:\n",
    "        x = x.split(\"%20\")\n",
    "        x = \" \".join(x)\n",
    "        return x\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86321fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['keyword'] = train['keyword'].apply(lambda x: CleanedKeyword(x))\n",
    "test['keyword'] = test['keyword'].apply(lambda x: CleanedKeyword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "726d0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'ablaze' 'accident' 'aftershock' 'airplane accident' 'ambulance'\n",
      " 'annihilated' 'annihilation' 'apocalypse' 'armageddon' 'army' 'arson'\n",
      " 'arsonist' 'attack' 'attacked' 'avalanche' 'battle' 'bioterror'\n",
      " 'bioterrorism' 'blaze' 'blazing' 'bleeding' 'blew up' 'blight' 'blizzard'\n",
      " 'blood' 'bloody' 'blown up' 'body bag' 'body bagging' 'body bags' 'bomb'\n",
      " 'bombed' 'bombing' 'bridge collapse' 'buildings burning'\n",
      " 'buildings on fire' 'burned' 'burning' 'burning buildings' 'bush fires'\n",
      " 'casualties' 'casualty' 'catastrophe' 'catastrophic' 'chemical emergency'\n",
      " 'cliff fall' 'collapse' 'collapsed' 'collide' 'collided' 'collision'\n",
      " 'crash' 'crashed' 'crush' 'crushed' 'curfew' 'cyclone' 'damage' 'danger'\n",
      " 'dead' 'death' 'deaths' 'debris' 'deluge' 'deluged' 'demolish'\n",
      " 'demolished' 'demolition' 'derail' 'derailed' 'derailment' 'desolate'\n",
      " 'desolation' 'destroy' 'destroyed' 'destruction' 'detonate' 'detonation'\n",
      " 'devastated' 'devastation' 'disaster' 'displaced' 'drought' 'drown'\n",
      " 'drowned' 'drowning' 'dust storm' 'earthquake' 'electrocute'\n",
      " 'electrocuted' 'emergency' 'emergency plan' 'emergency services'\n",
      " 'engulfed' 'epicentre' 'evacuate' 'evacuated' 'evacuation' 'explode'\n",
      " 'exploded' 'explosion' 'eyewitness' 'famine' 'fatal' 'fatalities'\n",
      " 'fatality' 'fear' 'fire' 'fire truck' 'first responders' 'flames'\n",
      " 'flattened' 'flood' 'flooding' 'floods' 'forest fire' 'forest fires'\n",
      " 'hail' 'hailstorm' 'harm' 'hazard' 'hazardous' 'heat wave' 'hellfire'\n",
      " 'hijack' 'hijacker' 'hijacking' 'hostage' 'hostages' 'hurricane'\n",
      " 'injured' 'injuries' 'injury' 'inundated' 'inundation' 'landslide' 'lava'\n",
      " 'lightning' 'loud bang' 'mass murder' 'mass murderer' 'massacre' 'mayhem'\n",
      " 'meltdown' 'military' 'mudslide' 'natural disaster' 'nuclear disaster'\n",
      " 'nuclear reactor' 'obliterate' 'obliterated' 'obliteration' 'oil spill'\n",
      " 'outbreak' 'pandemonium' 'panic' 'panicking' 'police' 'quarantine'\n",
      " 'quarantined' 'radiation emergency' 'rainstorm' 'razed' 'refugees'\n",
      " 'rescue' 'rescued' 'rescuers' 'riot' 'rioting' 'rubble' 'ruin'\n",
      " 'sandstorm' 'screamed' 'screaming' 'screams' 'seismic' 'sinkhole'\n",
      " 'sinking' 'siren' 'sirens' 'smoke' 'snowstorm' 'storm' 'stretcher'\n",
      " 'structural failure' 'suicide bomb' 'suicide bomber' 'suicide bombing'\n",
      " 'sunk' 'survive' 'survived' 'survivors' 'terrorism' 'terrorist' 'threat'\n",
      " 'thunder' 'thunderstorm' 'tornado' 'tragedy' 'trapped' 'trauma'\n",
      " 'traumatised' 'trouble' 'tsunami' 'twister' 'typhoon' 'upheaval'\n",
      " 'violent storm' 'volcano' 'war zone' 'weapon' 'weapons' 'whirlwind'\n",
      " 'wild fires' 'wildfire' 'windstorm' 'wounded' 'wounds' 'wreck' 'wreckage'\n",
      " 'wrecked']\n",
      "['' 'ablaze' 'accident' 'aftershock' 'airplane accident' 'ambulance'\n",
      " 'annihilated' 'annihilation' 'apocalypse' 'armageddon' 'army' 'arson'\n",
      " 'arsonist' 'attack' 'attacked' 'avalanche' 'battle' 'bioterror'\n",
      " 'bioterrorism' 'blaze' 'blazing' 'bleeding' 'blew up' 'blight' 'blizzard'\n",
      " 'blood' 'bloody' 'blown up' 'body bag' 'body bagging' 'body bags' 'bomb'\n",
      " 'bombed' 'bombing' 'bridge collapse' 'buildings burning'\n",
      " 'buildings on fire' 'burned' 'burning' 'burning buildings' 'bush fires'\n",
      " 'casualties' 'casualty' 'catastrophe' 'catastrophic' 'chemical emergency'\n",
      " 'cliff fall' 'collapse' 'collapsed' 'collide' 'collided' 'collision'\n",
      " 'crash' 'crashed' 'crush' 'crushed' 'curfew' 'cyclone' 'damage' 'danger'\n",
      " 'dead' 'death' 'deaths' 'debris' 'deluge' 'deluged' 'demolish'\n",
      " 'demolished' 'demolition' 'derail' 'derailed' 'derailment' 'desolate'\n",
      " 'desolation' 'destroy' 'destroyed' 'destruction' 'detonate' 'detonation'\n",
      " 'devastated' 'devastation' 'disaster' 'displaced' 'drought' 'drown'\n",
      " 'drowned' 'drowning' 'dust storm' 'earthquake' 'electrocute'\n",
      " 'electrocuted' 'emergency' 'emergency plan' 'emergency services'\n",
      " 'engulfed' 'epicentre' 'evacuate' 'evacuated' 'evacuation' 'explode'\n",
      " 'exploded' 'explosion' 'eyewitness' 'famine' 'fatal' 'fatalities'\n",
      " 'fatality' 'fear' 'fire' 'fire truck' 'first responders' 'flames'\n",
      " 'flattened' 'flood' 'flooding' 'floods' 'forest fire' 'forest fires'\n",
      " 'hail' 'hailstorm' 'harm' 'hazard' 'hazardous' 'heat wave' 'hellfire'\n",
      " 'hijack' 'hijacker' 'hijacking' 'hostage' 'hostages' 'hurricane'\n",
      " 'injured' 'injuries' 'injury' 'inundated' 'inundation' 'landslide' 'lava'\n",
      " 'lightning' 'loud bang' 'mass murder' 'mass murderer' 'massacre' 'mayhem'\n",
      " 'meltdown' 'military' 'mudslide' 'natural disaster' 'nuclear disaster'\n",
      " 'nuclear reactor' 'obliterate' 'obliterated' 'obliteration' 'oil spill'\n",
      " 'outbreak' 'pandemonium' 'panic' 'panicking' 'police' 'quarantine'\n",
      " 'quarantined' 'radiation emergency' 'rainstorm' 'razed' 'refugees'\n",
      " 'rescue' 'rescued' 'rescuers' 'riot' 'rioting' 'rubble' 'ruin'\n",
      " 'sandstorm' 'screamed' 'screaming' 'screams' 'seismic' 'sinkhole'\n",
      " 'sinking' 'siren' 'sirens' 'smoke' 'snowstorm' 'storm' 'stretcher'\n",
      " 'structural failure' 'suicide bomb' 'suicide bomber' 'suicide bombing'\n",
      " 'sunk' 'survive' 'survived' 'survivors' 'terrorism' 'terrorist' 'threat'\n",
      " 'thunder' 'thunderstorm' 'tornado' 'tragedy' 'trapped' 'trauma'\n",
      " 'traumatised' 'trouble' 'tsunami' 'twister' 'typhoon' 'upheaval'\n",
      " 'violent storm' 'volcano' 'war zone' 'weapon' 'weapons' 'whirlwind'\n",
      " 'wild fires' 'wildfire' 'windstorm' 'wounded' 'wounds' 'wreck' 'wreckage'\n",
      " 'wrecked']\n"
     ]
    }
   ],
   "source": [
    "print(train['keyword'].unique())\n",
    "print(test['keyword'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8ac63",
   "metadata": {},
   "source": [
    "# Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7220a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "def text_cleaning(text):\n",
    "    forbidden_words = set(stopwords.words('english'))\n",
    "    if text:\n",
    "        text = ' '.join(text.split('.'))\n",
    "        text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z0-9]', ' ', text.strip().lower())).strip()\n",
    "        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n",
    "        text = [word for word in text.split() if word not in forbidden_words]\n",
    "        return text\n",
    "    return []\n",
    "#clean data\n",
    "#this following cleaning is taken from https://www.kaggle.com/nxhong93/tweet-predict1\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"havent\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"thats\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"theres\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"theyre\":  \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"}\n",
    "\n",
    "puncts = puncts + list(string.punctuation)\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x).replace(\"\\n\",\"\")\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('\\d+', ' ', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispellings_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "\n",
    "    def replace(match):\n",
    "        return mispell_dict[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def remove_space(string):\n",
    "    string = BeautifulSoup(string).text.strip().lower()\n",
    "    string = re.sub(r'((http)\\S+)', 'http', string)\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    return string\n",
    "\n",
    "\n",
    "def clean_data(df, columns: list):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda x: remove_space(x).lower())        \n",
    "        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n",
    "        df[col] = df[col].apply(lambda x: clean_text(x))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66202b",
   "metadata": {},
   "source": [
    "# Add cleaned data to data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0b01446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0                   Our Deeds are the Reason of this #earthquake M...       1\n",
       "1                              Forest fire near La Ronge Sask. Canada       1\n",
       "2                   All residents asked to 'shelter in place' are ...       1\n",
       "3                   13,000 people receive #wildfires evacuation or...       1\n",
       "4                   Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faf62fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['location','text']:\n",
    "    train[col] = train[col].apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "    test[col] = test[col].apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "train = clean_data(train,['keyword','text'])\n",
    "test = clean_data(test,['keyword','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a303a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13 000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0                        deeds reason earthquake may allah forgive us       1\n",
       "1                               forest fire near la ronge sask canada       1\n",
       "2                   residents asked shelter place notified officer...       1\n",
       "3                   13 000 people receive wildfires evacuation ord...       1\n",
       "4                   got sent photo ruby alaska smoke wildfires pou...       1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "839b53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f40a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect location\n",
    "def DetectLocation(text):\n",
    "    doc = nlp(text)\n",
    "    entitles = []\n",
    "    for ent in doc.ents:\n",
    "        entitles.append(ent)\n",
    "    if len(entitles) > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d41740",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['original_location'] = train['location'].apply(lambda x: DetectLocation(x))\n",
    "test['original_location'] = test['location'].apply(lambda x: DetectLocation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4baa1b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>original_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>bbcmtd wholesale markets ablaze http co lhyxeo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>est september 2012 bristol</td>\n",
       "      <td>always try bring heavy metal rt http co yao1e0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>africa</td>\n",
       "      <td>africanbaze breaking news nigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>philadelphia pa</td>\n",
       "      <td>crying set ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>london uk</td>\n",
       "      <td>plus side look sky last night ablaze http co q...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>tn</td>\n",
       "      <td>bright side wrecked http co uea0txrhys</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>newcastleupontyne uk</td>\n",
       "      <td>widda16 gone relax thought wife wrecked cake g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>vancouver canada</td>\n",
       "      <td>three days work pretty much wrecked hahaha sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>london</td>\n",
       "      <td>fx forex trading cramer iger 3 words wrecked d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>engineshed great atmosphere british lion gig t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5006 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                    location  \\\n",
       "31     ablaze                  birmingham   \n",
       "32     ablaze  est september 2012 bristol   \n",
       "33     ablaze                      africa   \n",
       "34     ablaze             philadelphia pa   \n",
       "35     ablaze                   london uk   \n",
       "...       ...                         ...   \n",
       "7575  wrecked                          tn   \n",
       "7577  wrecked        newcastleupontyne uk   \n",
       "7579  wrecked            vancouver canada   \n",
       "7580  wrecked                      london   \n",
       "7581  wrecked                     lincoln   \n",
       "\n",
       "                                                   text  target  \\\n",
       "31    bbcmtd wholesale markets ablaze http co lhyxeo...       1   \n",
       "32    always try bring heavy metal rt http co yao1e0...       0   \n",
       "33    africanbaze breaking news nigeria flag set abl...       1   \n",
       "34                                    crying set ablaze       0   \n",
       "35    plus side look sky last night ablaze http co q...       0   \n",
       "...                                                 ...     ...   \n",
       "7575             bright side wrecked http co uea0txrhys       0   \n",
       "7577  widda16 gone relax thought wife wrecked cake g...       0   \n",
       "7579  three days work pretty much wrecked hahaha sho...       0   \n",
       "7580  fx forex trading cramer iger 3 words wrecked d...       0   \n",
       "7581  engineshed great atmosphere british lion gig t...       0   \n",
       "\n",
       "      original_location  \n",
       "31                    0  \n",
       "32                    1  \n",
       "33                    0  \n",
       "34                    1  \n",
       "35                    1  \n",
       "...                 ...  \n",
       "7575                  0  \n",
       "7577                  1  \n",
       "7579                  1  \n",
       "7580                  1  \n",
       "7581                  1  \n",
       "\n",
       "[5006 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['location'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "387d1973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'birmingham',\n",
       " 'est september 2012 bristol',\n",
       " 'africa',\n",
       " 'philadelphia pa',\n",
       " 'london uk',\n",
       " 'pretoria',\n",
       " 'world wide',\n",
       " 'paranaque city',\n",
       " 'live webcam',\n",
       " 'milky way',\n",
       " 'greensboro north carolina',\n",
       " 'england',\n",
       " 'sheffield township ohio',\n",
       " 'india',\n",
       " 'barbados',\n",
       " 'anaheim',\n",
       " 'abuja',\n",
       " 'usa',\n",
       " 'south africa',\n",
       " 'sao paulo brazil',\n",
       " 'hollywoodland',\n",
       " 'edmonton alberta treaty 6',\n",
       " 'inang pamantasan',\n",
       " 'twitter lockout progress',\n",
       " 'concord ca',\n",
       " 'calgary ab',\n",
       " 'san francisco',\n",
       " 'clvlnd',\n",
       " 'nashville tn',\n",
       " 'santa clara ca',\n",
       " 'uk',\n",
       " 'st louis mo',\n",
       " 'walker county alabama',\n",
       " 'australia',\n",
       " 'north carolina',\n",
       " 'norf carolina',\n",
       " 'san mateo county ca',\n",
       " 'njoro kenya',\n",
       " 'sister bedroom',\n",
       " 'arlington tx',\n",
       " 'south bloomfield oh',\n",
       " 'new hanover county nc',\n",
       " 'maldives',\n",
       " 'manchester nh',\n",
       " 'wilmington nc',\n",
       " 'global',\n",
       " 'alberta sask montana',\n",
       " 'charlotte',\n",
       " 'baton rouge la',\n",
       " 'hagerstown md',\n",
       " 'gloucestershire uk',\n",
       " 'nairobi kenya',\n",
       " 'instagram heyimginog',\n",
       " '304',\n",
       " 'switzerland',\n",
       " 'us',\n",
       " 'somewhere know',\n",
       " 'belgium',\n",
       " 'dope show',\n",
       " 'oshawa canada',\n",
       " 'baker city oregon',\n",
       " 'united states',\n",
       " 'marysville ca',\n",
       " 'hermosa beach ca',\n",
       " '19 600858 99 047821',\n",
       " 'pennsylvania',\n",
       " 'salt lake city utah',\n",
       " 'palo alto ca',\n",
       " 'spain opa locka fl',\n",
       " 'jaipur india',\n",
       " 'hyderabad telangana india',\n",
       " 'eagle pass texas',\n",
       " 'bangalore',\n",
       " 'financial news views',\n",
       " 'indonesia',\n",
       " 'boyfriends legs',\n",
       " 'new mexico usa',\n",
       " 'somewhere',\n",
       " 'mumbai india',\n",
       " 'sri lanka',\n",
       " 'u resident',\n",
       " 'lehigh valley pa',\n",
       " 'canada',\n",
       " 'thrissur',\n",
       " 'havenford',\n",
       " '92',\n",
       " 'israel',\n",
       " 'fashion heaven ig tmid',\n",
       " 'san francisco ca',\n",
       " 'italy',\n",
       " 'nyc',\n",
       " 'toronto',\n",
       " 'jackson',\n",
       " 'new york worldwide',\n",
       " 'new orleans la',\n",
       " 'west wales',\n",
       " 'happily married 2 kids',\n",
       " 'cambridge',\n",
       " 'arizona',\n",
       " 'mumbai',\n",
       " 'amsterdam',\n",
       " 'swindon england',\n",
       " 'williamstown vt',\n",
       " 'north carolina usa',\n",
       " 'karachi',\n",
       " 'loveland colorado',\n",
       " 'c h c g',\n",
       " 'l',\n",
       " 'visit youtube channel',\n",
       " 'lexington',\n",
       " 'hannover germany',\n",
       " 'playa',\n",
       " 'davidson nc',\n",
       " 'higher places',\n",
       " 'horsemind mi',\n",
       " 'new york ny',\n",
       " 'boksburg',\n",
       " 'v rp ozrp mv au r18',\n",
       " 'greater manchester uk',\n",
       " 'boston',\n",
       " 'canopy kingdom',\n",
       " 'zone layer',\n",
       " 'london',\n",
       " 'trancy manor',\n",
       " 'south 37',\n",
       " 'west lancashire uk',\n",
       " 'pa',\n",
       " 'views six',\n",
       " 'university toronto',\n",
       " 'swaning around',\n",
       " 'albany ny',\n",
       " 'california usa',\n",
       " 'wild wild web',\n",
       " 'subconscious la',\n",
       " 'spain',\n",
       " 'ca physically boston strong',\n",
       " 'yeezy taught nv',\n",
       " 'rock hill sc',\n",
       " 'coolidge az',\n",
       " 'republic texas',\n",
       " 'phoenix az',\n",
       " 'ljubljana slovenia',\n",
       " 'connecticut',\n",
       " 'tacoma washington',\n",
       " 'big houston boston denver',\n",
       " 'chandler az',\n",
       " 'colorado',\n",
       " 'sindria',\n",
       " 'texas',\n",
       " 'elk grove ca usa',\n",
       " 'shire',\n",
       " 'austin tx',\n",
       " 'oakland',\n",
       " 'albuquerque',\n",
       " 'buenos aires argentina',\n",
       " 'san antonio ish tx',\n",
       " 'oregon usa',\n",
       " 'harlingen tx',\n",
       " 'buffalo ny',\n",
       " 'las vegas',\n",
       " 'tokyo',\n",
       " 'california united states',\n",
       " 'flightcity uk',\n",
       " 'alphen aan den rijn holland',\n",
       " 'wrigley field',\n",
       " 'probably strip club',\n",
       " 'new york city',\n",
       " 'rotterdam zuid holland',\n",
       " 'derry 17',\n",
       " 'nowhere everywhere',\n",
       " 'florida usa',\n",
       " 'worldwide',\n",
       " 'east coast',\n",
       " 'california',\n",
       " 'orwellion police state',\n",
       " 'castaic ca',\n",
       " 'helsinki finland',\n",
       " 'east kilbride',\n",
       " 'middle eastern palace',\n",
       " 'kent',\n",
       " 'perthshire',\n",
       " 'twitch tv naturalemblem26',\n",
       " 'cyprus',\n",
       " 'memphis tn',\n",
       " 'studio',\n",
       " 'hollywood ca',\n",
       " 'new york',\n",
       " 'pakistan',\n",
       " 'mexico',\n",
       " 'campinas sp',\n",
       " 'harlem new york',\n",
       " 'washington dc',\n",
       " 'burbank ca',\n",
       " 'spokane washington',\n",
       " 'charlotte nc',\n",
       " 'empire state',\n",
       " 'jerusalem',\n",
       " 'kingston pennsylvania',\n",
       " 'milwaukee wi',\n",
       " 'zero branco',\n",
       " 'bajaur',\n",
       " 'eldoret kenya',\n",
       " 'miami fl',\n",
       " 'los angeles ca',\n",
       " 'north east region singapore',\n",
       " 'chicago',\n",
       " 'earth',\n",
       " 'jerusalem israel',\n",
       " 'menasha wi',\n",
       " 'ss',\n",
       " 'atlanta',\n",
       " 'bleak house',\n",
       " 'heccfidmss gmail com',\n",
       " 'blonde bi fry',\n",
       " 'america',\n",
       " 'nyc ex islamophobe',\n",
       " 'sf bay area',\n",
       " 'orange county california',\n",
       " 'winston salem north carolina',\n",
       " 'adelaide south australia',\n",
       " 'snapchat fvck casper',\n",
       " 'dallas tx',\n",
       " 'location',\n",
       " 'selena britney hilary',\n",
       " 'ireland',\n",
       " 'freeport il usa',\n",
       " 'dubai',\n",
       " 'tucson az',\n",
       " 'seattle wa',\n",
       " 'bellevue ne',\n",
       " 'west bank gaza strip',\n",
       " 'flg',\n",
       " 'scotland united kingdom',\n",
       " 'online 24 7 even kidding',\n",
       " 'rowyso dallas',\n",
       " 'halton ontario',\n",
       " 'portland oregon',\n",
       " 'fimak ist bolge muduru',\n",
       " 'unite blue',\n",
       " 'dayton ohio',\n",
       " 'ph',\n",
       " 'port jervis ny',\n",
       " 'city joy',\n",
       " 'texas usa',\n",
       " '1 3 blam squad',\n",
       " 'cch',\n",
       " 'atx',\n",
       " 'mauritius',\n",
       " 'akron ohio usa',\n",
       " 'london st catharines',\n",
       " 'peshawar',\n",
       " 'lealman florida',\n",
       " 'gdjb asot',\n",
       " 'groningen netherlands europe',\n",
       " 'livingston il u',\n",
       " 'arundel',\n",
       " 'anna maria fl',\n",
       " 'hammock fl usa',\n",
       " 'paulo sp brasil',\n",
       " 'dimitri arms',\n",
       " 'oslo norway',\n",
       " 'los angeles',\n",
       " 'loughton essex uk',\n",
       " 'guaravitas',\n",
       " 'score goals buying',\n",
       " 'london kent se england',\n",
       " 'score team goals buying',\n",
       " 'south central wales',\n",
       " 'jersey city new jersey',\n",
       " 'denver co',\n",
       " 'brasil',\n",
       " 'buy give money',\n",
       " '505 w maple suite 100',\n",
       " 'philippines',\n",
       " 'freeport il',\n",
       " 'world',\n",
       " 'danville va',\n",
       " 'uk great britain',\n",
       " 'san jose ca',\n",
       " 'use tmw tweets get rt',\n",
       " 'utah',\n",
       " 'wisconsin',\n",
       " 'west richland wa',\n",
       " 'chicago 312',\n",
       " 'washington c',\n",
       " 'nc',\n",
       " 'west virginia usa',\n",
       " 'british girl texas',\n",
       " 'silver spring md',\n",
       " 'atlanta ga',\n",
       " 'manhattan ny',\n",
       " 'wilmington de',\n",
       " 'memphis',\n",
       " 'itunes',\n",
       " 'oxford ms',\n",
       " 'pelham al',\n",
       " 'jacksonville fl',\n",
       " 'arkansas jonesboro',\n",
       " 'across atlantic',\n",
       " 'melbourne florida',\n",
       " 'moon',\n",
       " 'extraterrestrial highway',\n",
       " 'espoo finland',\n",
       " 'washington c area',\n",
       " 'oes 4th point sisstar ti',\n",
       " 'sydney new south wales',\n",
       " 'netherlands amsterdam virtual',\n",
       " 'hudson valley ny',\n",
       " 'timeline kamu',\n",
       " 'budapest hungary',\n",
       " 'searching bae',\n",
       " 'eagle mountain texas',\n",
       " 'columbus',\n",
       " 'temecula ca',\n",
       " 'fresno ca',\n",
       " 'raleigh durham nc',\n",
       " 'ducked',\n",
       " 'rio de janeiro',\n",
       " '302',\n",
       " 'columbus oh',\n",
       " 'mo city',\n",
       " 'tripsburg ms',\n",
       " 'durham n c',\n",
       " 'delhi',\n",
       " 'penn hills pa',\n",
       " 'southern california desert',\n",
       " 'gotham city',\n",
       " 'contac 27b80f7e 08170156520',\n",
       " 'pig symbol alabama',\n",
       " 'intramuros manila',\n",
       " 'world g g',\n",
       " 'worlds',\n",
       " 'state georgia',\n",
       " 'screen',\n",
       " 'lima peru',\n",
       " 'saltillo coahuila de zaragoza',\n",
       " 'suitland',\n",
       " 'everywhere',\n",
       " 'konoha',\n",
       " 'swag francisco',\n",
       " 'saint marys ga',\n",
       " 'nigeria',\n",
       " 'essex brighton',\n",
       " 'pennsylvania pa',\n",
       " 'rockford il',\n",
       " 'az',\n",
       " 'vero beach fl',\n",
       " 'middle',\n",
       " 'baltimore md',\n",
       " 'dmv fashion school ksu',\n",
       " 'nice places',\n",
       " 'quantico va',\n",
       " 'island lake il',\n",
       " 'live oak tx',\n",
       " 'gages lake il',\n",
       " 'madisonville tn',\n",
       " 'basketball city usa',\n",
       " 'aep',\n",
       " 'alberta pack',\n",
       " 'expelcl',\n",
       " 'heart ghost town',\n",
       " 'great state texas',\n",
       " 'alicante valencia',\n",
       " 'greensboro nc',\n",
       " 'indiana',\n",
       " 'local dump',\n",
       " 'seattle',\n",
       " 'southampton england',\n",
       " '205 478',\n",
       " 'waterford mi',\n",
       " 'iowa usa',\n",
       " 'va',\n",
       " 'florida',\n",
       " 'california mermaid',\n",
       " 'new york atl',\n",
       " 'usa florida via brooklyn ny',\n",
       " 'h pez sophia',\n",
       " 'brooklyn ny',\n",
       " 'queens ny',\n",
       " 'vancouver bc',\n",
       " 'ottawa canada',\n",
       " 'wherever',\n",
       " 'purgatory usa',\n",
       " 'calgary alberta',\n",
       " 'kama 18 france',\n",
       " 'sydney',\n",
       " 'maryland usa',\n",
       " 'daruka near tamworth nsw',\n",
       " 'ijmuiden netherlands',\n",
       " 'university heights ohio',\n",
       " 'central illinois',\n",
       " 'baton rouge',\n",
       " 'psn pipbois',\n",
       " 'colombo sri lanka',\n",
       " 'johannesburg south africa',\n",
       " 'mammy belly',\n",
       " 'uk ibiza',\n",
       " 'laventillemoorings',\n",
       " 'scotland',\n",
       " 'cleveland oh',\n",
       " 'detroit mi united states',\n",
       " 'guelph ontario canada',\n",
       " 'waterfront',\n",
       " 'columbus ohio',\n",
       " 'waukesha wi',\n",
       " 'himalayan mountains',\n",
       " 'colorado worldwide',\n",
       " 'ontario canada',\n",
       " 'houston tx',\n",
       " 'lakewood colorado',\n",
       " '6ix',\n",
       " 'washington usa',\n",
       " 'ideally big tree',\n",
       " 'conversing janet caf',\n",
       " 'dime palace',\n",
       " 'cairo egypt',\n",
       " 'bug forest',\n",
       " 'canberra',\n",
       " 'international',\n",
       " 'htx',\n",
       " 'punpunl ndia',\n",
       " 'itirapina paulo',\n",
       " 'north jersey',\n",
       " 'ewa beach hi',\n",
       " 'biloxi mississippi',\n",
       " 'buenos aires',\n",
       " 'brecksville oh',\n",
       " 'walthamstow london',\n",
       " 'malaysia',\n",
       " 'ivano frankivsk',\n",
       " 'sunshine coast queensland',\n",
       " 'england uk europe sol 3',\n",
       " 'nashua nh',\n",
       " 'leicester',\n",
       " '65',\n",
       " 'westchester',\n",
       " 'lynnfield',\n",
       " 'level 3 garrison sector g',\n",
       " 'singapore',\n",
       " 'glasgow',\n",
       " 'shity land northern ireland',\n",
       " 'christchurch new zealand',\n",
       " 'peekskill new york 10566',\n",
       " 'storybrooke',\n",
       " 'blanket',\n",
       " 'isolated city world perth',\n",
       " 'brazil',\n",
       " 'aus',\n",
       " 'santa cruz ca',\n",
       " 'inverness nova scotia',\n",
       " 'l z l h c h r c',\n",
       " 'oklahoma',\n",
       " '801 sl ut',\n",
       " 'fluffy cloud',\n",
       " '5th dimension',\n",
       " 'georgia',\n",
       " 'july 11th 2015',\n",
       " 'grey area',\n",
       " 'st paul mn',\n",
       " 'cobblestone',\n",
       " '30 307558 81 403118',\n",
       " 'cosmic oneness',\n",
       " 'guildford uk',\n",
       " 'nowhere islands smash manor',\n",
       " 'kisumu',\n",
       " 'making worldwide change near u',\n",
       " 'la oc vegas',\n",
       " 'london outlaw country',\n",
       " 'grimsby england',\n",
       " 'gotham',\n",
       " 'manchester world england',\n",
       " 'sitting eddie vedders lap',\n",
       " 'missouri usa',\n",
       " 'greenville sc',\n",
       " 'paignton',\n",
       " 'car travel',\n",
       " 'atl sea',\n",
       " '39 982988 75 261624',\n",
       " 'englewood chicago',\n",
       " '302 815',\n",
       " 'new',\n",
       " 'purple booth studio',\n",
       " 'cloud 9',\n",
       " 'former yugoslav republic macedonia',\n",
       " '3 3 7 slopelousas 2 2 5',\n",
       " '316',\n",
       " 'whereveri mat',\n",
       " 'huber heights oh',\n",
       " 'miami',\n",
       " 'every',\n",
       " '401 livin',\n",
       " 'mi',\n",
       " 'eptx',\n",
       " 'austin texas',\n",
       " 'oklahoma city',\n",
       " 'ca',\n",
       " 'united kingdom',\n",
       " 'westside philly 7 block',\n",
       " 'long island ny',\n",
       " 'waistdeep tx',\n",
       " 'c baltimore annapolis',\n",
       " '937 734',\n",
       " 'fife wa',\n",
       " 'bushkill pa',\n",
       " 'shadows',\n",
       " 'southwest tx',\n",
       " 'anywehere',\n",
       " 'menlo park sfo world',\n",
       " 'speaking truth love',\n",
       " 'aarhus central jutland',\n",
       " 'lincoln ne',\n",
       " 'wny',\n",
       " 'bolton tewkesbury uk',\n",
       " 'travelling tae pants',\n",
       " 'keli x',\n",
       " 'manchester',\n",
       " 'knoxville tn',\n",
       " 'chicagorobotz',\n",
       " 'whs 17',\n",
       " 'nv',\n",
       " 'lagos nigeria',\n",
       " 'edmonton alberta',\n",
       " 'gia kardashianempire',\n",
       " 'sunrise manor nv',\n",
       " 'oxford oh',\n",
       " 'odawara japan',\n",
       " 'chicago il',\n",
       " 'des moines ia',\n",
       " 'dundas ontario',\n",
       " 'idn',\n",
       " 'netherlands',\n",
       " 'dakounty pa',\n",
       " 'sseldorf germany',\n",
       " 'old blighty',\n",
       " 'land new jersey',\n",
       " 'atlanta georgia',\n",
       " 'rts endorsements',\n",
       " 'kabul tuebingen innsbruck',\n",
       " 'light dark form void',\n",
       " 'erbil',\n",
       " 'stockton tees teesside uk',\n",
       " 'screwston tx',\n",
       " 'old new england home',\n",
       " 'melbourne',\n",
       " 'cape town',\n",
       " 'ikeja nigeria',\n",
       " 'warwick ri dollarocracy also',\n",
       " 'texas university',\n",
       " 'shipwreck cove',\n",
       " 'sydney australia',\n",
       " 'overland park ks',\n",
       " 'swmo',\n",
       " 'puerto rico',\n",
       " 'toronto citizen canada us',\n",
       " 'silicon valley',\n",
       " 'north east usa',\n",
       " 'vit ria es',\n",
       " 'new delhi delhi',\n",
       " 'buscame el tu melte',\n",
       " 'wiltshire',\n",
       " 'proud indians',\n",
       " 'pittsburgh pa',\n",
       " 'mum del',\n",
       " 'leeds england',\n",
       " 'playa del carmen mexico',\n",
       " 'ny ct greece',\n",
       " 'mackay qld australia',\n",
       " 'quincy',\n",
       " 'nj',\n",
       " 'madison ga',\n",
       " 'kurvez gearheadcentral net',\n",
       " 'st charles md',\n",
       " 'denver colorado',\n",
       " 'ziam af',\n",
       " 'go blue hail yes',\n",
       " 'outside matrix think',\n",
       " 'hell',\n",
       " 'epic city bb',\n",
       " 'somewhere rainbow',\n",
       " 'selma2oakland',\n",
       " 'bombardment bay',\n",
       " 'savannah ga',\n",
       " 'dallas',\n",
       " 'new orleans louisiana',\n",
       " 'england united kingdom',\n",
       " 'dublin city ireland',\n",
       " 'new hampshire',\n",
       " 'intermountain west',\n",
       " 'tulsa oklahoma',\n",
       " 'auburn al',\n",
       " 'taken piper curda',\n",
       " 'nigeria global',\n",
       " 'fort walton beach fl',\n",
       " 'sweden',\n",
       " 'groton ct',\n",
       " 'brisbane australia',\n",
       " 'ny capital district',\n",
       " 'peoria',\n",
       " 'reading uk',\n",
       " 'concord nh',\n",
       " 'cornfields',\n",
       " 'worcester',\n",
       " 'roanoke va',\n",
       " 'via pa',\n",
       " 'oklahoma city ok',\n",
       " 'toronto dallas',\n",
       " 'san diego ca',\n",
       " 'germany',\n",
       " 'massachusetts',\n",
       " 'nxgerxa',\n",
       " 'erie pa',\n",
       " 'port charlotte fl',\n",
       " 'belleville illinois',\n",
       " 'alabama',\n",
       " 'long island ny san francisco',\n",
       " 'gainesville fl',\n",
       " 'oakland ca',\n",
       " '956',\n",
       " 'escondido ca',\n",
       " 'dc',\n",
       " 'chicago area',\n",
       " 'upper st clair pa',\n",
       " 'cherry creek denver co',\n",
       " '627',\n",
       " 'blogland',\n",
       " 'isle man',\n",
       " 'hampton roads va',\n",
       " 'gameday',\n",
       " 'earthling',\n",
       " 'black canyon new river az',\n",
       " 'caracas venezuela',\n",
       " 'ny',\n",
       " 'charlottetown',\n",
       " 'paradise nv',\n",
       " 'li ge',\n",
       " 'spokane washington 99206',\n",
       " 'taco bell',\n",
       " 'australian capital territory',\n",
       " 'http www amazon com dp b00hr',\n",
       " 'kate infp',\n",
       " 'sacramento ca',\n",
       " 'please h',\n",
       " 'ixwin',\n",
       " 'santiago bernabeau',\n",
       " 'e l',\n",
       " 'whiterun skyrim',\n",
       " 'greenpoint brooklyn',\n",
       " 'victoria british columbia',\n",
       " 'botanical garden probably',\n",
       " 'nelspruit south africa',\n",
       " 'midwest',\n",
       " 'copenhagen capital region denmark',\n",
       " 'spying thoughts',\n",
       " 'seattle grace mercy death',\n",
       " 'tucson arizona',\n",
       " 'charlotte county florida',\n",
       " 'head office united kingdom',\n",
       " 'mid north coast nsw',\n",
       " 'iphone 27 499212 153 011072',\n",
       " 'queen creek az',\n",
       " 'jamaica',\n",
       " 'trinidad tobago',\n",
       " 'melbourne australia',\n",
       " 'internet nyc',\n",
       " 'london bristol guildford',\n",
       " 'canberra australian capital territory',\n",
       " 'beacon hills',\n",
       " 'somewhere outside',\n",
       " 'wolmers trust school boys',\n",
       " 'loughborough',\n",
       " 'selangor',\n",
       " 'bronx new york',\n",
       " 'canadian bread',\n",
       " 'le moyne 16',\n",
       " 'hoxton london',\n",
       " 'las vegas nv usa',\n",
       " 'heinz field',\n",
       " 'skyport de la rosa',\n",
       " 'low cal calzone zone',\n",
       " 'brooklyn new york',\n",
       " '50 queanbeyan 50 sydney',\n",
       " 'insula barataria',\n",
       " 'afghanistan usa',\n",
       " 'inglewood ca',\n",
       " 'absecon nj',\n",
       " 'williamsbridge bronx new yor',\n",
       " 'northern kentucky usa',\n",
       " 'mostly yuin',\n",
       " 'nairobi',\n",
       " 'rochelle ga',\n",
       " 'south heaven',\n",
       " 'el dorado ks',\n",
       " 'santa monica ca',\n",
       " 'kenya',\n",
       " '1648 queen st west toronto',\n",
       " 'toledo oh',\n",
       " 'fairfield california',\n",
       " 'trinity bailiwick jersey',\n",
       " 'virginia',\n",
       " 'liverpool',\n",
       " 'boulder co',\n",
       " 'hospital bc skh vid',\n",
       " 'hartford london hong kong',\n",
       " '4skinchan arms',\n",
       " 'massachusetts usa',\n",
       " 'kansas city mo',\n",
       " 'wellington new zealand',\n",
       " 'new brunswick nj',\n",
       " 'city angels ca',\n",
       " 'morganville texas',\n",
       " 'america new zealand',\n",
       " 'stockholm sweden',\n",
       " 'azeroth',\n",
       " 'lytham st anne',\n",
       " 'ylisse',\n",
       " 'portugal',\n",
       " 'around world baby',\n",
       " 'untmdoutdoors r k',\n",
       " 'lima per',\n",
       " 'piedmont area north carolina',\n",
       " 'buxton venice nottingham',\n",
       " 'quito ecuador',\n",
       " 'inexpressible island',\n",
       " 'bouvet island',\n",
       " 'shirley ny',\n",
       " 'planet earth',\n",
       " 'paonia colorado',\n",
       " 'portland',\n",
       " 'dublin ireland',\n",
       " 'lurking',\n",
       " 'n',\n",
       " 'littleton co usa',\n",
       " 'virginia united states',\n",
       " 'center domestic preparedness',\n",
       " 'ukraine ireland',\n",
       " 'welt',\n",
       " 'wales',\n",
       " 'seattle washington',\n",
       " 'beaumont tx',\n",
       " 'annapolis md',\n",
       " 'las vegas nevada',\n",
       " 'harris county texas',\n",
       " 'tyler tx',\n",
       " 'evanston il',\n",
       " 'north ferriby east yorkshire',\n",
       " 'colombia',\n",
       " 'ames iowa',\n",
       " 'moscow russia',\n",
       " 'jersey city nj',\n",
       " 'mankato mn',\n",
       " 'orbost victoria australia',\n",
       " 'neverland',\n",
       " 'london england',\n",
       " 'da laundry mat wit nivea',\n",
       " 'norway',\n",
       " 'ad hawty',\n",
       " 'ny live easy',\n",
       " 'bestcoast',\n",
       " 'bc',\n",
       " 'abuja nigeria',\n",
       " 'colchester essex',\n",
       " 'livin life 610',\n",
       " 'suplex city',\n",
       " 'inside mind',\n",
       " '36 38',\n",
       " 'slappin smackin',\n",
       " 'draw circle earth',\n",
       " 'madrid comunidad de madrid',\n",
       " 'highland park ca',\n",
       " 'swan river',\n",
       " 'kolkata india',\n",
       " 'melrose',\n",
       " 'jubail ic saudi arabia',\n",
       " 'sugarhouse ut',\n",
       " 'lugo',\n",
       " 'chicago illinois',\n",
       " 'blackpool england uk',\n",
       " 'san jose california',\n",
       " 'fakefams',\n",
       " 'clouds',\n",
       " 'sandton south africa',\n",
       " 'bummerville otw',\n",
       " 'europe',\n",
       " 'brighton hove',\n",
       " 'pompano beach fl',\n",
       " 'jkt48 muse a7x',\n",
       " 'behind obama curtain',\n",
       " 'live',\n",
       " 'henderson nv',\n",
       " 'camarillo ca',\n",
       " 'manchester uk',\n",
       " 'eugene oregon',\n",
       " 'paris',\n",
       " 'kingston jamaica',\n",
       " 'spokane wa',\n",
       " 'standing behind',\n",
       " 'alexandria egypt',\n",
       " 'instagram chloe bellx',\n",
       " 'web',\n",
       " 'san francisco bay area',\n",
       " 'foreverwithbap 8',\n",
       " 'got7supportph',\n",
       " 'wherever fuck washington',\n",
       " 'ny scranton pa',\n",
       " 'perth western australia',\n",
       " 'melton ga',\n",
       " 'greg place',\n",
       " 'viejo',\n",
       " 'kansas free state kc',\n",
       " 'silang cavite para aque',\n",
       " 'fort smith ar',\n",
       " 'planeta h2o',\n",
       " 'www youtube com malkavius2',\n",
       " 'michigan',\n",
       " 'forever girl',\n",
       " 'esp rito santo',\n",
       " 'new york usa',\n",
       " 'ormond sea fl',\n",
       " 'maryland baltimore',\n",
       " 'pennsylvania usa',\n",
       " 'houston texas',\n",
       " 'yadkinville nc',\n",
       " 'medford nj',\n",
       " 'dallas texas',\n",
       " 'unnamed city',\n",
       " 'peterborough',\n",
       " '6 152261 106 775995',\n",
       " 'protectingtitan side',\n",
       " 'oregon',\n",
       " 'eau claire wisconsin',\n",
       " 'st joseph minnesota',\n",
       " 'torn town manchester',\n",
       " 'waco tx',\n",
       " 'tennessee',\n",
       " 'cape cod massachusetts usa',\n",
       " 'bk',\n",
       " 'lansing michigan',\n",
       " 'peterborough ont',\n",
       " 'court',\n",
       " 'traverse city mi',\n",
       " 'see barn bleakness',\n",
       " 'hertfordshire',\n",
       " '41 252426 96 072013',\n",
       " 'greeley co',\n",
       " 'soooota',\n",
       " 'sacramento',\n",
       " 'ny ny',\n",
       " 'arvada co',\n",
       " 'maryland',\n",
       " 'vancouver colombie britannique',\n",
       " 'irving texas',\n",
       " 'riverside ca',\n",
       " 'seattle wa usa',\n",
       " 'usa az',\n",
       " 'east atlanta georgia',\n",
       " 'saint lucia',\n",
       " 'peterborough ontario canada',\n",
       " 'north highlands ca',\n",
       " 'vancouver',\n",
       " '60th st ss',\n",
       " 'usa wa',\n",
       " 'btwn rock hard place',\n",
       " 'aix en provence france',\n",
       " '75 florida',\n",
       " '21 462446 158 022017',\n",
       " 'darlington',\n",
       " 'kenton ohio',\n",
       " 'galatians 2 20',\n",
       " 'charleston sc',\n",
       " 'lancaster pennsylvania usa',\n",
       " 'definitely stables',\n",
       " 'cuernavaca morelos xico',\n",
       " 'va beach virginia',\n",
       " '52 479722 62 184971',\n",
       " 'pig sty',\n",
       " 'bangor co',\n",
       " 'weston super mare',\n",
       " 'victoria tx',\n",
       " 'pakistan islamabad',\n",
       " 'gujranwala pakistan',\n",
       " 'lindenhurst',\n",
       " 'islamabad',\n",
       " 'far',\n",
       " 'kingswinford',\n",
       " 'love smurfs 2',\n",
       " 'viterbo bfa acting 18',\n",
       " 'kaneohe',\n",
       " 'houma la',\n",
       " 'eastatlanta westgeorgia 18',\n",
       " 'san antonio tx',\n",
       " 'cleveland ohio',\n",
       " 'san diego texas',\n",
       " '05 04 2014 18 23',\n",
       " 'bolivar mo',\n",
       " 'taking pain like pleasure',\n",
       " 'san fransokyo',\n",
       " 'washington dc native',\n",
       " 'w nykae',\n",
       " 'honeymoon avenue',\n",
       " 'toronto worldwide',\n",
       " '11 4 14',\n",
       " 'wherever netflix',\n",
       " 'hamont',\n",
       " 'u k',\n",
       " 'online',\n",
       " 'conroe tx',\n",
       " 'guayaquil',\n",
       " 'bahstun porta reeko',\n",
       " 'bucks county pa',\n",
       " 'sunny south florida',\n",
       " 'rio',\n",
       " 'chicago lake buena vista',\n",
       " 'toronto ontario',\n",
       " 'liberty lake wa',\n",
       " 'ankara malatya ad orontem',\n",
       " 'antioch california',\n",
       " 'state college pa',\n",
       " 'somewhere cali',\n",
       " 'im around jersey',\n",
       " 'garden grove',\n",
       " 'adelaide australia',\n",
       " 'bki kua',\n",
       " 'ur nus',\n",
       " 'illinois usa',\n",
       " 'aztec princess',\n",
       " 'turner fenton',\n",
       " 'kla uganda',\n",
       " 'uganda',\n",
       " '253',\n",
       " 'elkhart',\n",
       " 'pon di gully',\n",
       " 'benedict college',\n",
       " 'im lost',\n",
       " 'hamilton',\n",
       " 'des moines iowa',\n",
       " 'rural northern nevada',\n",
       " 'republic philippines',\n",
       " 'hyderabad',\n",
       " 'vancouver hq worldwide',\n",
       " 'quezon city philippines',\n",
       " 'geneva',\n",
       " 'hartford connecticut',\n",
       " 'sioux falls sd',\n",
       " 'cornwall',\n",
       " 'beside basketball',\n",
       " 'rome italy',\n",
       " 'tafekop ga matsepe',\n",
       " 'vilnius',\n",
       " 'made america',\n",
       " 'ps4 stop asking',\n",
       " 'cheshire london allover',\n",
       " 'bartholomew county indiana',\n",
       " 'u',\n",
       " 'mind world',\n",
       " 'catskills',\n",
       " 'columbia sc',\n",
       " 'right',\n",
       " 'lawrence ks via emporia ks',\n",
       " 'http twitch tv jcmonkey',\n",
       " 'unknown',\n",
       " 'marysville mi',\n",
       " 'new connecticut',\n",
       " 'austin san diego',\n",
       " 'pontevedra galicia',\n",
       " 'somewhere canada',\n",
       " 'london new york',\n",
       " '261 5th avenue new york ny',\n",
       " 'rockville maryland',\n",
       " 'conversation',\n",
       " 'usaov',\n",
       " 'bhopal madhya pradesh india',\n",
       " 'lemongang',\n",
       " 'ayr',\n",
       " 'loughborough england',\n",
       " 'killarney',\n",
       " 'lahar gwalior',\n",
       " 'lincoln il',\n",
       " 'spinning time',\n",
       " 'hailing dayton',\n",
       " 'newcastle upon tyne england',\n",
       " 'instagram trillrebel',\n",
       " 'always dying never resting',\n",
       " '2005',\n",
       " 'uruguay westeros gallifrey',\n",
       " 'jersey c',\n",
       " 'afghanistan',\n",
       " 'orlando fl',\n",
       " 'atmosphere',\n",
       " 'somewhere portugal',\n",
       " 'south stand',\n",
       " 'dundalk ireland',\n",
       " 'sochi kda ru',\n",
       " '26 695807 27 837865',\n",
       " '19 forever',\n",
       " 'kettering oh',\n",
       " 'spare oom',\n",
       " 'milton keynes',\n",
       " 'atl al',\n",
       " 'uptown',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e487d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_locations = ['place','room','home','somewhere','nowhere','everywhere','location',\n",
    "                  'dope','kidding','moon','wherever','dimension','world','fvck','fuck','beside']\n",
    "def is_location_spammy(text):\n",
    "    for word in spam_locations:\n",
    "        if word in text:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8dca600",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Is_location_spam'] = train['location'].apply(lambda x: is_location_spammy(x))\n",
    "test['Is_location_spam'] = test['location'].apply(lambda x: is_location_spammy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "091ac024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>original_location</th>\n",
       "      <th>Is_location_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13 000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target  \\\n",
       "0                        deeds reason earthquake may allah forgive us       1   \n",
       "1                               forest fire near la ronge sask canada       1   \n",
       "2                   residents asked shelter place notified officer...       1   \n",
       "3                   13 000 people receive wildfires evacuation ord...       1   \n",
       "4                   got sent photo ruby alaska smoke wildfires pou...       1   \n",
       "\n",
       "   original_location  Is_location_spam  \n",
       "0                  0                 0  \n",
       "1                  0                 0  \n",
       "2                  0                 0  \n",
       "3                  0                 0  \n",
       "4                  0                 0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b4da755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_counter(text):\n",
    "    \"\"\"detects any digit in any token and counts\n",
    "       once par token.\"\"\"\n",
    "    sum_number = 0\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        sum_number += bool(re.search(r'\\d', token.text))*1\n",
    "    return sum_number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98d3b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['digit_count_location'] = train['location'].apply(lambda x: digit_counter(x))\n",
    "test['digit_count_location'] = test['location'].apply(lambda x: digit_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72d49e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>original_location</th>\n",
       "      <th>Is_location_spam</th>\n",
       "      <th>digit_count_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13 000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target  \\\n",
       "0                        deeds reason earthquake may allah forgive us       1   \n",
       "1                               forest fire near la ronge sask canada       1   \n",
       "2                   residents asked shelter place notified officer...       1   \n",
       "3                   13 000 people receive wildfires evacuation ord...       1   \n",
       "4                   got sent photo ruby alaska smoke wildfires pou...       1   \n",
       "\n",
       "   original_location  Is_location_spam  digit_count_location  \n",
       "0                  0                 0                     0  \n",
       "1                  0                 0                     0  \n",
       "2                  0                 0                     0  \n",
       "3                  0                 0                     0  \n",
       "4                  0                 0                     0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd0268eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find different frequent words occuring in disaster tweets vs non-disaster tweets\n",
    "disaster_tweets =' '.join(train[train['target'] == 1]['text'].tolist())\n",
    "non_disaster_tweets = ' '.join(train[train['target'] == 0]['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42654838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def return_top_words(text,words = 10):\n",
    "    allWords = nltk.tokenize.word_tokenize(text)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if w not in stopwords)    \n",
    "    mostCommontuples= allWordExceptStopDist.most_common(words)\n",
    "    mostCommon = [tupl[0] for tupl in mostCommontuples]\n",
    "    return mostCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4752feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_disaster_words = return_top_words(disaster_tweets,50)\n",
    "top_50_nondisaster_words = return_top_words(non_disaster_tweets,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ba71a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['co',\n",
       " 'http',\n",
       " 'fire',\n",
       " 'news',\n",
       " 'amp',\n",
       " 'disaster',\n",
       " 'via',\n",
       " 'california',\n",
       " 'suicide',\n",
       " 'police',\n",
       " 'people',\n",
       " '2',\n",
       " 'killed',\n",
       " 'like',\n",
       " 'hiroshima',\n",
       " 'storm',\n",
       " 'fires',\n",
       " 'crash',\n",
       " 'families',\n",
       " 'train',\n",
       " 'emergency',\n",
       " 'bomb',\n",
       " 'buildings',\n",
       " 'two',\n",
       " 'nuclear',\n",
       " 'mh370',\n",
       " 'attack',\n",
       " 'video',\n",
       " 'wildfire',\n",
       " 'accident',\n",
       " 'bombing',\n",
       " 'old',\n",
       " 'get',\n",
       " 'one',\n",
       " '1',\n",
       " 'dead',\n",
       " 'northern',\n",
       " 'burning',\n",
       " 'legionnaires',\n",
       " 'car',\n",
       " 'bomber',\n",
       " 'pm',\n",
       " 'u',\n",
       " 'war',\n",
       " 'year',\n",
       " 'homes',\n",
       " 'typhoon',\n",
       " 'new',\n",
       " 'still',\n",
       " 'obama']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50_disaster_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffdea402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['co',\n",
       " 'http',\n",
       " 'like',\n",
       " 'amp',\n",
       " 'new',\n",
       " 'get',\n",
       " 'one',\n",
       " 'body',\n",
       " '2',\n",
       " 'would',\n",
       " 'via',\n",
       " 'video',\n",
       " 'people',\n",
       " 'got',\n",
       " 'love',\n",
       " 'day',\n",
       " 'know',\n",
       " 'time',\n",
       " 'back',\n",
       " '3',\n",
       " 'full',\n",
       " 'see',\n",
       " 'emergency',\n",
       " 'us',\n",
       " 'going',\n",
       " 'youtube',\n",
       " 'u',\n",
       " 'let',\n",
       " 'still',\n",
       " 'gt',\n",
       " 'fire',\n",
       " 'go',\n",
       " 'want',\n",
       " 'good',\n",
       " 'man',\n",
       " 'think',\n",
       " 'rt',\n",
       " 'world',\n",
       " 'na',\n",
       " 'lol',\n",
       " 'life',\n",
       " 'first',\n",
       " 'news',\n",
       " 'way',\n",
       " 'burning',\n",
       " 'last',\n",
       " 'make',\n",
       " 'best',\n",
       " '5',\n",
       " 'really']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50_nondisaster_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e262cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_disaster_words = return_top_words(disaster_tweets,400)\n",
    "top_200_nondisaster_words = return_top_words(non_disaster_tweets,400)\n",
    "top_disaster_exclusive = list(set(top_200_disaster_words).difference(set(top_200_nondisaster_words)))\n",
    "top_nondisaster_exclusive = list(set(top_200_nondisaster_words).difference(set(top_200_disaster_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ee660a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['village',\n",
       " 'bomber',\n",
       " 'media',\n",
       " 'trains',\n",
       " 'rainstorm',\n",
       " 'charged',\n",
       " 'kill',\n",
       " 'rain',\n",
       " 'america',\n",
       " 'crisis',\n",
       " 'national',\n",
       " 'caused',\n",
       " 'horror',\n",
       " 'massacre',\n",
       " 'declaration',\n",
       " 'least',\n",
       " 'possible',\n",
       " 'water',\n",
       " 'fight',\n",
       " 'warning',\n",
       " 'rescuers',\n",
       " 'saudi',\n",
       " 'helicopter',\n",
       " 'trench',\n",
       " 'evacuation',\n",
       " 'land',\n",
       " 'north',\n",
       " 'crashed',\n",
       " 'collided',\n",
       " 'rd',\n",
       " 'issued',\n",
       " 'air',\n",
       " 'east',\n",
       " 'boy',\n",
       " 'murderer',\n",
       " 'bodies',\n",
       " 'weather',\n",
       " 'terrorism',\n",
       " 'update',\n",
       " 'hiroshima',\n",
       " 'shot',\n",
       " 'due',\n",
       " 'pkk',\n",
       " 'temple',\n",
       " 'severe',\n",
       " 'south',\n",
       " 'northern',\n",
       " 'reunion',\n",
       " 'pm',\n",
       " 'airplane',\n",
       " '16',\n",
       " 'earthquake',\n",
       " 'past',\n",
       " 'sinkhole',\n",
       " 'flash',\n",
       " 'fatal',\n",
       " 'hurricane',\n",
       " 'casualties',\n",
       " 'reuters',\n",
       " 'affected',\n",
       " 'street',\n",
       " 'youth',\n",
       " 'violent',\n",
       " 'picking',\n",
       " 'japan',\n",
       " 'hostage',\n",
       " 'hailstorm',\n",
       " 'india',\n",
       " 'manslaughter',\n",
       " 'says',\n",
       " 'three',\n",
       " 'calgary',\n",
       " 'b',\n",
       " 'use',\n",
       " 'suspect',\n",
       " 'aircraft',\n",
       " 'memories',\n",
       " 'refugio',\n",
       " 'traffic',\n",
       " 'security',\n",
       " 'island',\n",
       " 'outrage',\n",
       " 'american',\n",
       " 'cyclone',\n",
       " 'bigger',\n",
       " 'migrants',\n",
       " 'famine',\n",
       " 'st',\n",
       " 'arson',\n",
       " 'soudelor',\n",
       " 'train',\n",
       " 'bestnaijamade',\n",
       " 'government',\n",
       " 'heavy',\n",
       " 'plane',\n",
       " 'bush',\n",
       " 'west',\n",
       " 'coaches',\n",
       " 'derailed',\n",
       " 'natural',\n",
       " 'volcano',\n",
       " 'malaysia',\n",
       " 'crews',\n",
       " 'county',\n",
       " 'n',\n",
       " 'evacuated',\n",
       " 'displaced',\n",
       " 'killed',\n",
       " 'engulfed',\n",
       " 'wounded',\n",
       " 'razed',\n",
       " 'saw',\n",
       " 'minute',\n",
       " 'flooding',\n",
       " 'kills',\n",
       " 'died',\n",
       " 'detonated',\n",
       " 'amid',\n",
       " 'hazardous',\n",
       " 'suicide',\n",
       " 'airport',\n",
       " 'state',\n",
       " 'fedex',\n",
       " 'wildfire',\n",
       " 'floods',\n",
       " 'e',\n",
       " 'officials',\n",
       " 'projected',\n",
       " 'aug',\n",
       " 'mp',\n",
       " 'fires',\n",
       " '50',\n",
       " 'costlier',\n",
       " 'collision',\n",
       " 'lives',\n",
       " 'bioterror',\n",
       " 'disea',\n",
       " 'israeli',\n",
       " '00',\n",
       " 'california',\n",
       " 'tragedy',\n",
       " 'libya',\n",
       " 'mosque',\n",
       " 'signs',\n",
       " '08',\n",
       " 'august',\n",
       " 'site',\n",
       " 'dust',\n",
       " 'turkey',\n",
       " '0',\n",
       " 'oil',\n",
       " 'latest',\n",
       " 'devastation',\n",
       " '06',\n",
       " 'bridge',\n",
       " 'drought',\n",
       " 'obama',\n",
       " 'experts',\n",
       " 'bombing',\n",
       " 'theater',\n",
       " 'spill',\n",
       " '25',\n",
       " 'found',\n",
       " 'iran',\n",
       " 'mh370',\n",
       " 'bioterrorism',\n",
       " '16yr',\n",
       " 'investigators',\n",
       " 'hundreds',\n",
       " 'power',\n",
       " 'debris',\n",
       " '01',\n",
       " 'refugees',\n",
       " 'hail',\n",
       " 'boat',\n",
       " 'murder',\n",
       " 'pic',\n",
       " 'failure',\n",
       " '40',\n",
       " 'structural',\n",
       " 'evacuate',\n",
       " 'abc',\n",
       " '05',\n",
       " 'sue',\n",
       " 'hostages',\n",
       " 'searching',\n",
       " 'devastated',\n",
       " 'pakistan',\n",
       " 'wreckage',\n",
       " 'terrorist',\n",
       " 'wave',\n",
       " 'mph',\n",
       " 'outbreak',\n",
       " 'bus',\n",
       " 'muslims',\n",
       " 'catastrophic',\n",
       " 'virgin',\n",
       " 'near',\n",
       " 'lab',\n",
       " 'anniversary',\n",
       " 'wind',\n",
       " 'area',\n",
       " 'deaths',\n",
       " 'wild',\n",
       " 'breaking',\n",
       " 'report',\n",
       " 'feared',\n",
       " 'attacked',\n",
       " 'c',\n",
       " 'tornado',\n",
       " 'christian',\n",
       " 'legionnaires',\n",
       " 'landslide',\n",
       " 'issues',\n",
       " '70',\n",
       " 'saved',\n",
       " 'shooting',\n",
       " 'missing',\n",
       " 'isis',\n",
       " 'mount',\n",
       " 'building',\n",
       " 'service',\n",
       " 'confirmed',\n",
       " 'sandstorm',\n",
       " 'marks',\n",
       " 'closed',\n",
       " 'families',\n",
       " 'derailment',\n",
       " 'survivors',\n",
       " 'nagasaki',\n",
       " 'thunderstorm',\n",
       " 'forest',\n",
       " 'saipan',\n",
       " 'fatalities',\n",
       " 'officer',\n",
       " 'la',\n",
       " 'flag',\n",
       " 'fukushima',\n",
       " 'injured',\n",
       " 'must',\n",
       " 'conclusively',\n",
       " '15',\n",
       " 'swallowed',\n",
       " 'group',\n",
       " '30',\n",
       " 'typhoon',\n",
       " 'declares',\n",
       " 'myanmar',\n",
       " 'homes',\n",
       " 'post',\n",
       " 'hijacker',\n",
       " 'rioting',\n",
       " 'released',\n",
       " 'atomic',\n",
       " 'road',\n",
       " 'heat']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_disaster_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f176b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cross',\n",
       " 'beautiful',\n",
       " 'remember',\n",
       " 'something',\n",
       " 'x',\n",
       " 'bc',\n",
       " 'pick',\n",
       " 'keep',\n",
       " 'horrible',\n",
       " 'nothing',\n",
       " 'thanks',\n",
       " 'loud',\n",
       " 'wrecked',\n",
       " 'sorry',\n",
       " 'exploded',\n",
       " 'policy',\n",
       " 'mudslide',\n",
       " 'thing',\n",
       " 'screaming',\n",
       " 'girl',\n",
       " 'find',\n",
       " 'making',\n",
       " 'liked',\n",
       " 'yet',\n",
       " 'destruction',\n",
       " 'survive',\n",
       " 'away',\n",
       " 'tv',\n",
       " 'upheaval',\n",
       " 'wait',\n",
       " 'heard',\n",
       " 'whirlwind',\n",
       " 'jobs',\n",
       " 'top',\n",
       " 'explode',\n",
       " 'smoke',\n",
       " 'spot',\n",
       " 'maybe',\n",
       " 'everything',\n",
       " 'fall',\n",
       " 'always',\n",
       " 'danger',\n",
       " 'big',\n",
       " 'blew',\n",
       " 'blight',\n",
       " 'obliterated',\n",
       " 'game',\n",
       " 'makes',\n",
       " 'finally',\n",
       " 'really',\n",
       " 'great',\n",
       " 'desolation',\n",
       " 'things',\n",
       " 'happy',\n",
       " 'summer',\n",
       " 'phone',\n",
       " 'save',\n",
       " 'panicking',\n",
       " 'deluge',\n",
       " 'fear',\n",
       " 'die',\n",
       " 'sure',\n",
       " 'online',\n",
       " 'change',\n",
       " 'guy',\n",
       " 'crushed',\n",
       " 'yeah',\n",
       " 'ebay',\n",
       " 'chemical',\n",
       " 'windstorm',\n",
       " 'collide',\n",
       " 'content',\n",
       " 'full',\n",
       " 'quarantined',\n",
       " 'traumatised',\n",
       " 'data',\n",
       " 'anything',\n",
       " 'sirens',\n",
       " 'song',\n",
       " 'pretty',\n",
       " 'low',\n",
       " 'part',\n",
       " 'ass',\n",
       " 'cool',\n",
       " 'book',\n",
       " 'side',\n",
       " 'im',\n",
       " 'electrocute',\n",
       " 'bagging',\n",
       " 'real',\n",
       " 'sinking',\n",
       " 'bags',\n",
       " 'mayhem',\n",
       " 'battle',\n",
       " 'ruin',\n",
       " 'aftershock',\n",
       " 'reddit',\n",
       " 'oh',\n",
       " 'riot',\n",
       " 'wreck',\n",
       " 'gets',\n",
       " 'hat',\n",
       " 'shoulder',\n",
       " 'ever',\n",
       " 'annihilated',\n",
       " 'demolition',\n",
       " 'person',\n",
       " 'brown',\n",
       " 'demolished',\n",
       " 'harm',\n",
       " 'coming',\n",
       " 'trouble',\n",
       " 'screamed',\n",
       " 'drown',\n",
       " 'well',\n",
       " 'much',\n",
       " 'made',\n",
       " 'let',\n",
       " 'screams',\n",
       " 'apocalypse',\n",
       " 'desolate',\n",
       " 'used',\n",
       " 'banned',\n",
       " 'bang',\n",
       " 'stock',\n",
       " 'feeling',\n",
       " 'free',\n",
       " 'lava',\n",
       " 'believe',\n",
       " 'yes',\n",
       " 'blood',\n",
       " 'whole',\n",
       " 'siren',\n",
       " 'flattened',\n",
       " 'nowplaying',\n",
       " 'bad',\n",
       " 'injuries',\n",
       " 'market',\n",
       " 'blown',\n",
       " 'someone',\n",
       " 'left',\n",
       " 'words',\n",
       " 'curfew',\n",
       " 'body',\n",
       " 'tsunami',\n",
       " 'put',\n",
       " 'trapped',\n",
       " 'baby',\n",
       " 'obliteration',\n",
       " 'guys',\n",
       " 'zone',\n",
       " 'blizzard',\n",
       " 'obliterate',\n",
       " 'bloody',\n",
       " 'soon',\n",
       " 'woman',\n",
       " 'lord',\n",
       " 'survived',\n",
       " 'hours',\n",
       " 'okay',\n",
       " 'job',\n",
       " 'cake',\n",
       " 'blazing',\n",
       " 'leather',\n",
       " 'eyes',\n",
       " 'injury',\n",
       " 'deluged',\n",
       " 'hellfire',\n",
       " 'meltdown',\n",
       " 'avalanche',\n",
       " 'fatality',\n",
       " 'ball',\n",
       " 'lot',\n",
       " 'actually',\n",
       " 'self',\n",
       " 'thank',\n",
       " 'came',\n",
       " 'probably',\n",
       " 'inundated',\n",
       " 'gon',\n",
       " 'demolish',\n",
       " 'send',\n",
       " 'destroy',\n",
       " 'feel',\n",
       " 'ur',\n",
       " 'cliff',\n",
       " 'white',\n",
       " 'heart',\n",
       " 'god',\n",
       " 'start',\n",
       " 'also',\n",
       " 'electrocuted',\n",
       " 'burned',\n",
       " 'show',\n",
       " 'fan',\n",
       " 'fucking',\n",
       " 'kids',\n",
       " 'read',\n",
       " 'bag',\n",
       " 'lol',\n",
       " 'pandemonium',\n",
       " 'week',\n",
       " 'love',\n",
       " 'twister',\n",
       " 'hell',\n",
       " 'panic',\n",
       " 'fun',\n",
       " 'offensive',\n",
       " 'without',\n",
       " 'hazard',\n",
       " 'tomorrow',\n",
       " 'every',\n",
       " 'wounds',\n",
       " 'everyone',\n",
       " 'space',\n",
       " 'hey',\n",
       " 'face',\n",
       " 'stay',\n",
       " 'wan',\n",
       " 'play',\n",
       " 'crush',\n",
       " 'wrong',\n",
       " 'night',\n",
       " 'quarantine',\n",
       " 'destroyed',\n",
       " 'collapsed',\n",
       " 'mom',\n",
       " 'want',\n",
       " 'already',\n",
       " 'listen',\n",
       " 'check',\n",
       " 'music',\n",
       " 'bar',\n",
       " 'derail',\n",
       " 'fuck',\n",
       " 'detonation',\n",
       " 'goes',\n",
       " 'r',\n",
       " 'catastrophe',\n",
       " 'stretcher',\n",
       " 'light',\n",
       " 'sunk',\n",
       " 'care',\n",
       " 'twitter',\n",
       " 'drowning',\n",
       " 'armageddon',\n",
       " 'sound',\n",
       " 'better',\n",
       " 'trying',\n",
       " 'thought',\n",
       " 'stand',\n",
       " 'head',\n",
       " 'long',\n",
       " 'detonate',\n",
       " 'bleeding',\n",
       " 'went']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nondisaster_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91fe5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = top_disaster_exclusive + top_nondisaster_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b90a42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in total_vocab:\n",
    "    train['Is_'+word+'_present'] = train['text'].apply(lambda x: (word in x)*1)\n",
    "    test['Is_'+word+'_present'] = test['text'].apply(lambda x: (word in x)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c5f2472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>original_location</th>\n",
       "      <th>Is_location_spam</th>\n",
       "      <th>digit_count_location</th>\n",
       "      <th>Is_village_present</th>\n",
       "      <th>Is_bomber_present</th>\n",
       "      <th>Is_media_present</th>\n",
       "      <th>...</th>\n",
       "      <th>Is_sound_present</th>\n",
       "      <th>Is_better_present</th>\n",
       "      <th>Is_trying_present</th>\n",
       "      <th>Is_thought_present</th>\n",
       "      <th>Is_stand_present</th>\n",
       "      <th>Is_head_present</th>\n",
       "      <th>Is_long_present</th>\n",
       "      <th>Is_detonate_present</th>\n",
       "      <th>Is_bleeding_present</th>\n",
       "      <th>Is_went_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13 000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target  \\\n",
       "0                        deeds reason earthquake may allah forgive us       1   \n",
       "1                               forest fire near la ronge sask canada       1   \n",
       "2                   residents asked shelter place notified officer...       1   \n",
       "3                   13 000 people receive wildfires evacuation ord...       1   \n",
       "4                   got sent photo ruby alaska smoke wildfires pou...       1   \n",
       "\n",
       "   original_location  Is_location_spam  digit_count_location  \\\n",
       "0                  0                 0                     0   \n",
       "1                  0                 0                     0   \n",
       "2                  0                 0                     0   \n",
       "3                  0                 0                     0   \n",
       "4                  0                 0                     0   \n",
       "\n",
       "   Is_village_present  Is_bomber_present  Is_media_present  ...  \\\n",
       "0                   0                  0                 0  ...   \n",
       "1                   0                  0                 0  ...   \n",
       "2                   0                  0                 0  ...   \n",
       "3                   0                  0                 0  ...   \n",
       "4                   0                  0                 0  ...   \n",
       "\n",
       "   Is_sound_present  Is_better_present  Is_trying_present  Is_thought_present  \\\n",
       "0                 0                  0                  0                   0   \n",
       "1                 0                  0                  0                   0   \n",
       "2                 0                  0                  0                   0   \n",
       "3                 0                  0                  0                   0   \n",
       "4                 0                  0                  0                   0   \n",
       "\n",
       "   Is_stand_present  Is_head_present  Is_long_present  Is_detonate_present  \\\n",
       "0                 0                0                0                    0   \n",
       "1                 0                0                0                    0   \n",
       "2                 0                0                0                    0   \n",
       "3                 0                0                0                    0   \n",
       "4                 0                0                0                    0   \n",
       "\n",
       "   Is_bleeding_present  Is_went_present  \n",
       "0                    0                0  \n",
       "1                    0                0  \n",
       "2                    0                0  \n",
       "3                    0                0  \n",
       "4                    0                0  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e51339a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         max_features = 5000,\n",
    "                         smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(train['text'])\n",
    "X_test_tfidf = tf_idf.transform(test['text'])\n",
    "tf_kw = TfidfVectorizer(ngram_range = (1,2),\n",
    "                        binary = True,\n",
    "                        max_features = 1500,\n",
    "                        smooth_idf = False)\n",
    "kw_train_tfidf = tf_kw.fit_transform(train['keyword'])\n",
    "kw_test_tfidf = tf_kw.transform(test['keyword'])\n",
    "tf_location = TfidfVectorizer(ngram_range = (1,2),\n",
    "                              binary = True,\n",
    "                              max_features = 1500,\n",
    "                              smooth_idf = False)\n",
    "location_train_tfidf = tf_location.fit_transform(train['location'])\n",
    "location_test_tfidf = tf_location.transform(test['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eed44cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,pd.DataFrame(X_train_tfidf.toarray(),\n",
    "                                                columns = ['text_contains_'+ str(text) for text in tf_idf.get_feature_names()]),\n",
    "                        pd.DataFrame(kw_train_tfidf.toarray(),\n",
    "                                     columns = ['keyword_contains_'+str(text) for text in tf_kw.get_feature_names()]),\n",
    "                        pd.DataFrame(location_train_tfidf.toarray(),\n",
    "                                     columns = ['location_contains_'+str(text) for text in tf_location.get_feature_names()])],axis = 1)\n",
    "test = pd.concat([test,pd.DataFrame(X_test_tfidf.toarray(),\n",
    "                                              columns = ['text_contains_'+ str(text) for text in tf_idf.get_feature_names()]),\n",
    "                       pd.DataFrame(kw_test_tfidf.toarray(),\n",
    "                                    columns = ['keyword_contains_'+str(text) for text in tf_kw.get_feature_names()]),\n",
    "                       pd.DataFrame(location_test_tfidf.toarray(),\n",
    "                                    columns = ['location_contains_'+str(text) for text in tf_location.get_feature_names()])],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d62e7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                  7613\n",
      "unique                                                 7488\n",
      "top       11 year old boy charged manslaughter toddler r...\n",
      "freq                                                     10\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    if col == 'text':\n",
    "        print(train[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c5cd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vec(dataframe):\n",
    "    texts = dataframe['text'].tolist()\n",
    "    vectors = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        vectors.append(list(doc.vector))\n",
    "    df = pd.DataFrame(vectors,columns = ['vec_'+str(i) for i in range(96)])\n",
    "    return df\n",
    "vec_train = create_vec(train)\n",
    "vec_test = create_vec(test)\n",
    "train = pd.concat([train,vec_train],axis = 1)\n",
    "test = pd.concat([test,vec_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d48cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['keyword','location','text'],axis = 1)\n",
    "test = test.drop(['keyword','location','text'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9973dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop('target',axis = 1)\n",
    "Y_train = train['target']\n",
    "print('target' in test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12058b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:,~X_train.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5649d16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7378"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6feb208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6399579666360173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67      2932\n",
      "           1       0.84      0.59      0.69      4681\n",
      "\n",
      "    accuracy                           0.68      7613\n",
      "   macro avg       0.70      0.71      0.68      7613\n",
      "weighted avg       0.73      0.68      0.68      7613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.metrics import classification_report\n",
    "forest = rfc(n_estimators = 128,max_depth = 8,min_samples_split = 15,\n",
    "             class_weight = {0:1,1:1.6},oob_score = True)\n",
    "forest.fit(X_train,Y_train)\n",
    "print(forest.oob_score_)\n",
    "Y_pred_train = forest.predict(X_train)\n",
    "print(classification_report(Y_pred_train,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01fcb26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          features  feature_importances\n",
      "2766            text_contains_http             0.030537\n",
      "7339                        vec_58             0.030183\n",
      "1543              text_contains_co             0.024112\n",
      "7355                        vec_74             0.021694\n",
      "2767         text_contains_http co             0.015949\n",
      "...                            ...                  ...\n",
      "3508  text_contains_muslims temple             0.000000\n",
      "3507         text_contains_muslims             0.000000\n",
      "3506          text_contains_muslim             0.000000\n",
      "3505     text_contains_music video             0.000000\n",
      "3688          text_contains_opened             0.000000\n",
      "\n",
      "[7377 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "features = list(X_train.columns)\n",
    "feature_importances = forest.feature_importances_\n",
    "data = pd.DataFrame()\n",
    "data['features'] = features\n",
    "data['feature_importances'] = feature_importances\n",
    "data = data.sort_values(by = 'feature_importances',ascending = False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dfd0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features = data[data['feature_importances']<0.001]['features'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcbc2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = X_train.drop(bad_features,axis = 1)\n",
    "test_data_reduced = test.drop(bad_features,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd6ebcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 167)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a2fe84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6483646394325496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68      3300\n",
      "           1       0.78      0.59      0.68      4313\n",
      "\n",
      "    accuracy                           0.68      7613\n",
      "   macro avg       0.69      0.69      0.68      7613\n",
      "weighted avg       0.70      0.68      0.68      7613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = rfc(n_estimators = 128,max_depth = 5,min_samples_split = 15,\n",
    "             class_weight = {0:1,1:1.53},\n",
    "             oob_score = True)\n",
    "forest.fit(X_train_reduced,Y_train)\n",
    "print(forest.oob_score_)\n",
    "Y_pred_train = forest.predict(X_train_reduced)\n",
    "print(classification_report(Y_pred_train,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa40ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def get_auc_CV(model,X_train,Y_train):\n",
    "    \"\"\"\n",
    "    Return the average AUC score from cross-validation.\n",
    "    \"\"\"\n",
    "    # Set KFold to shuffle data before the split\n",
    "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Get AUC scores\n",
    "    auc = cross_val_score(\n",
    "        model, X_train, Y_train, scoring=\"roc_auc\", cv=kf)\n",
    "\n",
    "    return auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d78738ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4342\n",
      "           1       1.00      0.99      0.99      3271\n",
      "\n",
      "    accuracy                           0.99      7613\n",
      "   macro avg       0.99      0.99      0.99      7613\n",
      "weighted avg       0.99      0.99      0.99      7613\n",
      "\n",
      "Time consumed for training: 132.393\n",
      "Time consumed for prediction: 1.97983 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "xgb = XGBClassifier(n_estimators=200,learning_rate = 0.2,max_depth = 8)\n",
    "training_start = time.perf_counter()\n",
    "xgb.fit(X_train, Y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "pred_final = xgb.predict(test)\n",
    "pred_train = xgb.predict(X_train)\n",
    "print(classification_report(Y_train,pred_train))\n",
    "prediction_end = time.perf_counter()\n",
    "#acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "xgb_train_time = training_end-training_start\n",
    "xgb_prediction_time = prediction_end-prediction_start\n",
    "#print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "print(\"Time consumed for training: %4.3f\" % (xgb_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1413ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8227390165315036"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_CV(xgb,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8684f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "035b26ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('C:/Users/user/OneDrive/Desktop/nlp_twitter/nlp-getting-started/sample_submission.csv')\n",
    "print(sample_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef8d0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "dataframe['id'] = sample_submission['id']\n",
    "dataframe['target'] = pred_final\n",
    "dataframe.to_csv(\"C:/Users/user/OneDrive/Desktop/nlp_twitter/nlp-getting-started/final_submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00403249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
